<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>DoubleApp: My Personal Index Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">DoubleApp
   </div>
   <div id="projectbrief">Software Architecture Assignemnt integrating Speech Recognition and Double Positioning with bluetooth beacons</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">My Personal Index Page </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="objective_sec"></a>
Objective</h1>
<p>The objective of this project is to create and IOS App to move the Double Robot using the localization services provided by Estimote Beacons and integrate the motion control with the Speech Recognition services provided by Bing Speech API and the Intent Detection provided by LUIS.ai.</p>
<h1><a class="anchor" id="accomplishment_sec"></a>
Accomplishments</h1>
<ul>
<li>
Build a comprhensive user interface with: <ul>
<li>
buttons to: <ul>
<li>
enable/disable speech recognition </li>
<li>
move the Double </li>
<li>
enlongate/shorten the Double pole </li>
<li>
deploy/retract the kickstands </li>
</ul>
</li>
<li>
labels to show <ul>
<li>
the state of the Speech Recognition(Enabled, Disabled, Listening) </li>
<li>
speech recognition results: <ul>
<li>
phrases recognized with theris confidence level </li>
<li>
Intent with the highest score ad its score </li>
<li>
Type and values of the Entities relative to the Intent </li>
</ul>
</li>
<li>
Double position (x, y, orientation) </li>
</ul>
</li>
</ul>
</li>
<li>
Commute vocal commands in something the Double is able to process </li>
<li>
Move the Double toward a fixed goal position given by a vocal command <ul>
<li>
Double uses the goal position and its initial orientation to rotate toward the goal </li>
<li>
Double moves toward the goal until the goal is within a certain range or the estimated travel time has elapsed (backup condition) </li>
</ul>
</li>
<li>
Make a test of the trigonometry calculations used to rotate the double toward the goal. </li>
<li>
Disable the autonomous mode (stop the Double) whenever a button is pushed (security). </li>
<li>
Make the Double change its state (deploy/retract kickstands, elongate/shorten the pole) using vocal commands </li>
<li>
Make the Double recognize if it is in a certain range of a Beacon and act accordingly (Proximity Beacon) </li>
<li>
Build Estimote locations using the coordinates of corner points and Beacons </li>
</ul>
<h1><a class="anchor" id="limits_sec"></a>
Limitations of the systems</h1>
<ul>
<li>
The code written to enable continous speech recognition works with iOS 8.3 while it doesn't with iOS 11 </li>
<li>
For the ipad, the only available location manager mode is the lite one: <ul>
<li>
position accuracy +/-2.62 m instead of +/-1 m </li>
<li>
lower position update frequency </li>
</ul>
</li>
<li>
Orientation for the ipad is available only for ios 9.0+ </li>
<li>
When building using the offiial app the orientation is counted clockwise from the y-axis; in order to make standard trigonometry calculations a manual map must be built with the orientation which goes from 0 on the x-axis and is counted from the x-axis to the y-axis. </li>
<li>
Position given by the beacons fluctuates a lot and the accuracy is very poor </li>
<li>
The App for semi-auto mapping the location has poor pefrormances, better use the location builder class </li>
<li>
Double Control SDK has no documentation </li>
<li>
Nearables can be used only with the official app (no SDK yet) </li>
<li>
<p class="startli">Info from encoders not available, it could be because the firmware version of th Double is lower than 10 (<a href="https://github.com/doublerobotics/Basic-Control-SDK-iOS/commit/5f1e5920d76ad5370d0cb6375aa379ac7c6b3e98)">DoubleControlSDK Commit</a>)</p>
<p class="endli"></p>
</li>
</ul>
<h1><a class="anchor" id="arch_sec"></a>
Software Architecture</h1>
<h2><a class="anchor" id="arch_scheme"></a>
Architecture Scheme</h2>
<div class="image">
<img src="architecture.jpg"  style="width:50%"/>
</div>
<h2><a class="anchor" id="arch_descr"></a>
Architecture Description</h2>
<p>After launching the app you can either control the Double Robot manually with the buttons on the interface or start the speech recognition by pushing the start rec green button. When the speech recognition is activated the registration are sent to the speech recognition server through webscoket connection and the result phrases are sent to the view controller and to the LUIS service. The LUIS service parses the the phrases and sends the highest scoring recognized intent with relative entities to the view controller. If a intent: none is parsed the view controller should stop the microphone then send an adequate string to the vocal synthetizer. Else if a processable intent is detected it is translated into a command for the double. For security the Double command buttons on the interface have higher priority then the autonomous mode, so whenever a command button is pushed the Double stops whichever action it was doing. In the specific case a goToAction intent with a known entity of type room is detected, the double shold move autonomously toward the room fixed a priory position. In order to do this, the current position of the Double (x, y, orientation), published by Estimote localization each 0.2 seconds, is used to detrmine the movements the robot must perform. The view controller is responsible for what the app does in the foreground, while the app delegate is responsible for the background behaviour. If the double gets close/far to/from a proximity beacon or viceversa, the app delegate sends an adequate string to the vocal synthetizer.</p>
<h1><a class="anchor" id="sdkandtools_sec"></a>
SDK and Tools</h1>
<ul>
<li>
Xcode: an integrated development enviroment (IDE) for macOS containing a suite of software development tools needed to develop iOS Apps </li>
<li>
SpeechSDK: Bing Speech API cognitive services for speech recognition </li>
<li>
Luis (Language Understanding Intelligent Service): extract the meaning of a phrase in a format which can be directly used in the code (JSON) </li>
<li>
EstimoteProximitySDK: trigger actions when the distance of the device from a proximity beacon gets over/under a certain threshold </li>
<li>
EstiomoteIndoorSDK: makes position(x, y, orientation) available to the device </li>
<li>
EstimoteSDK </li>
<li>
DoubleControlSDK </li>
<li>
AVFoundation: speech synthetizer API </li>
</ul>
<h1><a class="anchor" id="howtorun_sec"></a>
How to run</h1>
<ol>
<li>
iOS must be at least 11.0 </li>
<li>
check if the subscription key of the Bing Speech API is still valid, if this is not the case get a new one </li>
<li>
USE THE WORKSPACE FILE (NOT THE PROJECT FILE) WHEN OPENING XCODE </li>
<li>
set IPHONE to 1 if you are using an iphone or set it to 0 if you are using an ipad </li>
<li>
if you want to build a new rectangular map <ol>
<li>
set MAP_FROM_CLOUD to 0 </li>
<li>
insert the coordinates of the corner points and of the loaction beacons in the section of the code relative to the location builder </li>
<li>
run the code </li>
<li>
substitue the location identifier with the one provided in the log </li>
</ol>
</li>
<li>
set MAP_FROM_CLOUD to 1 and set the location identifier of the desired location </li>
<li>
download the App to your device </li>
<li>
follow the instructions shown in the user interface </li>
</ol>
<p>Remember from the limitation section that the coninuous behaviour of the speech recognition is not working from the moment ipad iOS was updated from version 8.3 to version 11.0</p>
<h1><a class="anchor" id="futuredev_sec"></a>
Future Devevelopments</h1>
<ul>
<li>
find a way to re-enable the continous speech recognition behaviour, possible solutions are: <ul>
<li>
Use a silence detector within the app to determine when to connect to the server to perform the speech recognition </li>
<li>
Use the endMicandRecognition method before restarting the speech recognition (startMicAndRecognition method) after a final response is recieved. This could lead to a clean closure of the service before it restarts. </li>
<li>
Reinitialize the speech recognition client each time a final response is recieved </li>
</ul>
</li>
<li>
create a function to stop the micrphone before the double speaks and reactivate it afterwards in order to prevent it from looping on its own speech. </li>
<li>
update the firmware of the Double to the version 10.0 to be able to get informations from the encoders and integrate them with the bluetooth positioning system. </li>
<li>
create a websocket connection between devices to share positions and develop a method to follow moving goals </li>
</ul>
<h1><a class="anchor" id="appendix_sec"></a>
Appendix</h1>
<h2><a class="anchor" id="trig_sec"></a>
Trigonometry</h2>
<div class="image">
<img src="trigonometry.png"  style="width:50%"/>
</div>
<h2><a class="anchor" id="interface_sec"></a>
User Interface</h2>
<div class="image">
<img src="interface.jpg"  style="width:30%"/>
</div>
<h1><a class="anchor" id="biblio_sec"></a>
Bibliography</h1>
<p><a href="https://github.com/Azure-Samples/Cognitive-Speech-STT-iOS">SpeechRecognitionSDK</a></p>
<p><a href="://www.luis.ai/welcome">LUIS</a></p>
<p><a href="https://www.doublerobotics.com/double2.html">DoubleRobot</a></p>
<p><a href="https://developer.apple.com/av-foundation/">AVFoundation</a></p>
<p><a href="https://github.com/Estimote/iOS-Indoor-SDK">EstimoteIndoorLocationSDK</a></p>
<p><a href="https://github.com/doublerobotics/Basic-Control-SDK-iOS">DoubleControlSDK</a></p>
<p><a href="https://cocoapods.org/">cocoapods</a></p>
<p><a href="https://developer.estimote.com/proximity/ios-tutorial/">EstimoteProximity</a> </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
